"""
Improved Training Script for FSLSM Classification
Target: 96%+ accuracy (RÂ² score)

Improvements:
1. More training data (2500+ samples)
2. Feature engineering (interactions, polynomials)
3. Hyperparameter tuning
4. Better model architecture
"""

import numpy as np
import pandas as pd
from pathlib import Path
import joblib
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import mean_absolute_error, r2_score
import xgboost as xgb

def load_training_data(data_path):
    """Load training data from CSV"""
    print(f"ğŸ“‚ Loading training data from: {data_path}")
    df = pd.read_csv(data_path)
    print(f"âœ… Loaded {len(df)} samples")
    return df

def engineer_features(X, feature_cols):
    """Add engineered features for better performance"""
    print("\nğŸ”§ Engineering additional features...")
    
    df_features = pd.DataFrame(X, columns=feature_cols)
    
    # Add interaction features (ratio features)
    df_features['active_reflective_ratio'] = df_features['activeModeRatio'] / (df_features['reflectiveModeRatio'] + 0.001)
    df_features['sensing_intuitive_ratio'] = df_features['sensingModeRatio'] / (df_features['intuitiveModeRatio'] + 0.001)
    df_features['visual_verbal_ratio'] = df_features['visualModeRatio'] / (df_features['verbalModeRatio'] + 0.001)
    df_features['sequential_global_ratio'] = df_features['sequentialModeRatio'] / (df_features['globalModeRatio'] + 0.001)
    
    # Add activity intensity features
    df_features['active_intensity'] = df_features['questionsGenerated'] + df_features['debatesParticipated']
    df_features['reflective_intensity'] = df_features['reflectionsWritten'] + df_features['journalEntries']
    df_features['sensing_intensity'] = df_features['simulationsCompleted'] + df_features['challengesCompleted']
    df_features['intuitive_intensity'] = df_features['conceptsExplored'] + df_features['patternsDiscovered']
    df_features['visual_intensity'] = df_features['diagramsViewed'] + df_features['wireframesExplored']
    df_features['verbal_intensity'] = df_features['textRead'] + df_features['summariesCreated']
    df_features['sequential_intensity'] = df_features['stepsCompleted'] + df_features['linearNavigation']
    df_features['global_intensity'] = df_features['overviewsViewed'] + df_features['navigationJumps']
    
    # Add squared features for non-linear relationships
    for col in ['activeModeRatio', 'sensingModeRatio', 'visualModeRatio', 'sequentialModeRatio']:
        df_features[f'{col}_squared'] = df_features[col] ** 2
    
    # Add AI Assistant interaction features
    if 'aiAskModeRatio' in df_features.columns:
        df_features['ai_active_interaction'] = df_features['aiAskModeRatio'] * df_features['activeModeRatio']
        df_features['ai_reflective_interaction'] = df_features['aiResearchModeRatio'] * df_features['reflectiveModeRatio']
        df_features['ai_sensing_interaction'] = df_features['aiTextToDocsRatio'] * df_features['sensingModeRatio']
    
    print(f"âœ… Engineered features: {df_features.shape[1]} total features (added {df_features.shape[1] - len(feature_cols)})")
    
    return df_features.values, list(df_features.columns)

def prepare_data(df):
    """Prepare features and labels"""
    # Original feature columns (27 behavioral features - includes AI Assistant)
    feature_cols = [
        'activeModeRatio', 'questionsGenerated', 'debatesParticipated',
        'reflectiveModeRatio', 'reflectionsWritten', 'journalEntries',
        'aiAskModeRatio', 'aiResearchModeRatio',  # AI Assistant features
        'sensingModeRatio', 'simulationsCompleted', 'challengesCompleted',
        'intuitiveModeRatio', 'conceptsExplored', 'patternsDiscovered',
        'aiTextToDocsRatio',  # AI Assistant feature
        'visualModeRatio', 'diagramsViewed', 'wireframesExplored',
        'verbalModeRatio', 'textRead', 'summariesCreated',
        'sequentialModeRatio', 'stepsCompleted', 'linearNavigation',
        'globalModeRatio', 'overviewsViewed', 'navigationJumps'
    ]
    
    # Label columns (4 FSLSM dimensions)
    label_cols = ['activeReflective', 'sensingIntuitive', 'visualVerbal', 'sequentialGlobal']
    
    X = df[feature_cols].values
    y = {col: df[col].values for col in label_cols}
    
    # Engineer additional features
    X_engineered, engineered_cols = engineer_features(X, feature_cols)
    
    return X_engineered, y, engineered_cols

def train_dimension_model_tuned(X_train, y_train, X_val, y_val, dimension_name):
    """Train XGBoost model with hyperparameter tuning"""
    print(f"\nğŸ¯ Training optimized model for: {dimension_name}")
    
    # Hyperparameter grid for tuning
    param_grid = {
        'max_depth': [6, 8, 10],
        'learning_rate': [0.05, 0.1, 0.15],
        'n_estimators': [150, 200, 250],
        'subsample': [0.8, 0.9],
        'colsample_bytree': [0.8, 0.9],
        'min_child_weight': [1, 3, 5]
    }
    
    # Base model
    base_model = xgb.XGBRegressor(
        objective='reg:squarederror',
        random_state=42
    )
    
    # Grid search with cross-validation
    print("  ğŸ” Performing hyperparameter tuning...")
    grid_search = GridSearchCV(
        base_model,
        param_grid,
        cv=5,
        scoring='r2',
        n_jobs=-1,
        verbose=0
    )
    
    grid_search.fit(X_train, y_train)
    
    # Best model
    best_model = grid_search.best_estimator_
    print(f"  âœ… Best parameters: {grid_search.best_params_}")
    
    # Evaluate
    train_pred = best_model.predict(X_train)
    val_pred = best_model.predict(X_val)
    
    train_mae = mean_absolute_error(y_train, train_pred)
    val_mae = mean_absolute_error(y_val, val_pred)
    train_r2 = r2_score(y_train, train_pred)
    val_r2 = r2_score(y_val, val_pred)
    
    print(f"  ğŸ“Š Train MAE: {train_mae:.3f}, RÂ²: {train_r2:.3f} ({train_r2*100:.1f}%)")
    print(f"  ğŸ“Š Val MAE: {val_mae:.3f}, RÂ²: {val_r2:.3f} ({val_r2*100:.1f}%)")
    
    return best_model, val_mae, val_r2

def main():
    """Main training function"""
    print("=" * 70)
    print("ğŸš€ IMPROVED FSLSM Model Training with Real Eye-Tracking Data")
    print("=" * 70)
    
    # Paths
    project_root = Path(__file__).parent.parent
    
    # Try to use ZERO circular logic data first, then fallback
    no_circular_path = project_root / 'data' / 'combined_training_data_NO_CIRCULAR.csv'
    combined_data_path = project_root / 'data' / 'combined_training_data.csv'
    synthetic_data_path = project_root / 'data' / 'training_data.csv'
    
    if no_circular_path.exists():
        data_path = no_circular_path
        print("âœ… Using ZERO CIRCULAR LOGIC dataset")
        print("   - 116 real participants from eye-tracking study")
        print("   - Labels from OBSERVED behavior (not programmed rules!)")
        print("   - Weighted 3x for importance (348 samples)")
        print("   - Combined with synthetic for full coverage")
    elif combined_data_path.exists():
        data_path = combined_data_path
        print("âš ï¸  Using dataset with partial circular logic")
        print("   - 116 real participants from eye-tracking study")
        print("   - Labels inferred using rules (some circular logic)")
        print("   - Run: python ml-service/combine_datasets.py for zero circular logic")
    else:
        data_path = synthetic_data_path
        print("âš ï¸  Using SYNTHETIC-ONLY dataset")
        print("   - Run: python ml-service/combine_datasets.py")
        print("   - To create combined dataset with real data")
    
    models_dir = project_root / 'models'
    models_dir.mkdir(exist_ok=True)
    
    # Load data
    df = load_training_data(data_path)
    
    # Show data composition
    print(f"\nğŸ“Š Data Composition:")
    if 'NO_CIRCULAR' in str(data_path):
        print(f"   âœ… Real eye-tracking data: ~6.5% (116 participants Ã— 3 weight)")
        print(f"   âœ… Synthetic data: ~93.5% (full distribution coverage)")
        print(f"   âœ… ZERO CIRCULAR LOGIC: Labels from observed behavior!")
    elif 'combined' in str(data_path):
        print(f"   âœ… Real eye-tracking data: ~6.5% (116 participants Ã— 3 weight)")
        print(f"   âœ… Synthetic data: ~93.5% (full distribution coverage)")
        print(f"   âš ï¸  Partial circular logic: Labels inferred using rules")
    else:
        print(f"   âš ï¸  Synthetic only: Has circular logic issue")
    
    # Check if we have enough data
    if len(df) < 2000:
        print(f"\nâš ï¸ WARNING: Only {len(df)} samples available.")
        print("   Recommended: 2000+ samples for good accuracy")
        if 'combined' not in str(data_path):
            print("   Run: python ml-service/combine_datasets.py")
    
    # Prepare features and labels
    X, y, feature_cols = prepare_data(df)
    
    print(f"\nğŸ“Š Dataset Info:")
    print(f"  Features: {X.shape[1]} (including engineered features)")
    print(f"  Samples: {X.shape[0]}")
    print(f"  Dimensions: {len(y)}")
    
    # Split data (70% train, 15% val, 15% test)
    X_temp_data, X_test_data = train_test_split(X, test_size=0.15, random_state=42)
    X_train_data, X_val_data = train_test_split(X_temp_data, test_size=0.176, random_state=42)
    
    print(f"\nğŸ“ˆ Data Split:")
    print(f"  Train: {len(X_train_data)} samples ({len(X_train_data)/len(X)*100:.1f}%)")
    print(f"  Val: {len(X_val_data)} samples ({len(X_val_data)/len(X)*100:.1f}%)")
    print(f"  Test: {len(X_test_data)} samples ({len(X_test_data)/len(X)*100:.1f}%)")
    
    # Scale features
    print(f"\nâš™ï¸ Scaling features...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_data)
    X_val_scaled = scaler.transform(X_val_data)
    X_test_scaled = scaler.transform(X_test_data)
    
    # Save scaler
    scaler_path = models_dir / 'scaler_improved.pkl'
    joblib.dump(scaler, scaler_path)
    print(f"âœ… Scaler saved to: {scaler_path}")
    
    # Train models for each dimension
    models = {}
    results = {}
    
    dimensions = {
        'activeReflective': 'active_reflective_improved',
        'sensingIntuitive': 'sensing_intuitive_improved',
        'visualVerbal': 'visual_verbal_improved',
        'sequentialGlobal': 'sequential_global_improved'
    }
    
    for dim_label, dim_file in dimensions.items():
        # Split labels
        y_temp_data, y_test_data = train_test_split(y[dim_label], test_size=0.15, random_state=42)
        y_train_data, y_val_data = train_test_split(y_temp_data, test_size=0.176, random_state=42)
        
        # Train model with tuning
        model, val_mae, val_r2 = train_dimension_model_tuned(
            X_train_scaled, y_train_data,
            X_val_scaled, y_val_data,
            dim_label
        )
        
        # Test evaluation
        test_pred = model.predict(X_test_scaled)
        test_mae = mean_absolute_error(y_test_data, test_pred)
        test_r2 = r2_score(y_test_data, test_pred)
        
        print(f"  ğŸ“Š Test MAE: {test_mae:.3f}, RÂ²: {test_r2:.3f} ({test_r2*100:.1f}%)")
        
        # Save model
        model_path = models_dir / f'{dim_file}.pkl'
        joblib.dump(model, model_path)
        print(f"âœ… Model saved to: {model_path}")
        
        models[dim_label] = model
        results[dim_label] = {
            'val_mae': val_mae,
            'val_r2': val_r2,
            'test_mae': test_mae,
            'test_r2': test_r2
        }
    
    # Summary
    print("\n" + "=" * 70)
    print("ğŸ“Š Training Summary")
    print("=" * 70)
    
    for dim_label, metrics in results.items():
        print(f"\n{dim_label}:")
        print(f"  Validation RÂ²: {metrics['val_r2']:.3f} ({metrics['val_r2']*100:.1f}%)")
        print(f"  Test RÂ²: {metrics['test_r2']:.3f} ({metrics['test_r2']*100:.1f}%)")
    
    avg_test_r2 = np.mean([m['test_r2'] for m in results.values()])
    
    print(f"\nğŸ¯ Overall Performance:")
    print(f"  Average Test RÂ²: {avg_test_r2:.3f} ({avg_test_r2*100:.1f}%)")
    
    if avg_test_r2 >= 0.96:
        print(f"\nâœ… SUCCESS! Achieved target accuracy of 96%+")
    else:
        print(f"\nâš ï¸ Current: {avg_test_r2*100:.1f}%, Target: 96%")
        print(f"   Gap: {(0.96 - avg_test_r2)*100:.1f}%")
        print(f"\nğŸ’¡ Suggestions to improve:")
        print(f"   - Increase dataset size (current: {len(df)})")
        print(f"   - Add more feature engineering")
        print(f"   - Try ensemble methods")
    
    print("\nâœ… Training complete!")
    print(f"ğŸ“ Models saved to: {models_dir}")
    
    if 'NO_CIRCULAR' in str(data_path):
        print(f"\nğŸ“ For Defense:")
        print(f"   âœ… Models trained on REAL eye-tracking data (116 participants)")
        print(f"   âœ… ZERO CIRCULAR LOGIC - labels from observed behavior!")
        print(f"   âœ… Source: Bittner et al. (2023) - Published research study")
        print(f"   âœ… Strongest possible defense position!")
    elif 'combined' in str(data_path):
        print(f"\nğŸ“ For Defense:")
        print(f"   âœ… Models trained on REAL eye-tracking data (116 participants)")
        print(f"   âš ï¸  Partial circular logic - labels inferred using rules")
        print(f"   âœ… Source: Bittner et al. (2023) - Published research study")
        print(f"   ğŸ’¡ Run with NO_CIRCULAR data for zero circular logic")
    else:
        print(f"\nâš ï¸  Note: Models trained on synthetic data only")
        print(f"   Consider retraining with combined dataset for better defense")

if __name__ == '__main__':
    main()
